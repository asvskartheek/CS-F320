{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1b1nepCv_wAhuH2-boyhkv1Fo87vOlQmz",
      "authorship_tag": "ABX9TyO12pdl5huhFlQ/3hjefOTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asvskartheek/CS-F320/blob/master/training_notebooks/Training_Zivy_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q datasets setfit optuna"
      ],
      "metadata": {
        "id": "Gj2bhsMas_Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuHXmPuFs55H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from setfit import SetFitModel, TrainingArguments, Trainer, SetFitTrainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "TEST_SIZE = 500\n",
        "SEED = 0"
      ],
      "metadata": {
        "id": "Ol4KeK_vtFR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Zivy Files/labelled_17_apr.csv\") #18 apr, 4.19pm - 3203 dataset\n",
        "df.dropna(subset=['category'], how='all', inplace=True) # these nan's are coming from skipped labelling messages\n",
        "df = df[['body', 'category', 'channel_name', 'previous_messages', 'future_messages']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "W3b2u6XNtH3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['category'].value_counts().sort_index().plot(kind='bar', rot=0, ylabel='count')"
      ],
      "metadata": {
        "id": "eXgoQnAatXxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage 1 data preparation\n",
        "df_stage1 = df.copy()\n",
        "df_stage1['important'] = df_stage1['category'].apply(lambda x: 1 if x in ['FYI', 'Action Items'] else 0)\n",
        "df_train, df_s1_test = train_test_split(df_stage1, test_size=500, stratify=df_stage1['category'], random_state=0)\n",
        "df_s1_train, df_s1_val = train_test_split(df_train, test_size=0.1, stratify=df_train['important'], random_state=0)\n",
        "\n",
        "# Stage 2 data preparation\n",
        "df_stage2 = df_train[df_train['category'].isin(['FYI', 'Action Items'])]\n",
        "df_s2_train, df_s2_val = train_test_split(df_stage2, test_size=0.1, stratify=df_stage2['category'], random_state=0)\n",
        "\n",
        "len(df_s1_train), len(df_s1_val), len(df_s1_test), len(df_s2_train), len(df_s2_val) # S1 - train, val & test, S2 - train, val"
      ],
      "metadata": {
        "id": "7wq6Ewh9tUqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 1"
      ],
      "metadata": {
        "id": "bQtOeglntdj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_s1_train['category'].value_counts().sort_index().plot(kind='bar', rot=0, ylabel='count')"
      ],
      "metadata": {
        "id": "YHQFtTyX8dAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_s1_train['important'].value_counts().sort_index().plot(kind='bar', rot=0, ylabel='count')"
      ],
      "metadata": {
        "id": "EWTjRYmV8giM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_s1_test['important'].value_counts().sort_index().plot(kind='bar', rot=0, ylabel='count')"
      ],
      "metadata": {
        "id": "ZhGxR0oc8uOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_s1_test['category'].value_counts().sort_index().plot(kind='bar', rot=0, ylabel='count')"
      ],
      "metadata": {
        "id": "5-nh1jR280eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_s1_test['important'].value_counts().sort_index().plot(kind='bar', rot=0, ylabel='count')"
      ],
      "metadata": {
        "id": "7b4O28IeaG94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1_ds = {\n",
        "    'train': Dataset.from_pandas(df_s1_train, preserve_index=False),\n",
        "    'val': Dataset.from_pandas(df_s1_val, preserve_index=False),\n",
        "    'test': Dataset.from_pandas(df_s1_test, preserve_index=False)\n",
        "}"
      ],
      "metadata": {
        "id": "PZRKzYUUv1rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1_ds = {\n",
        "    'train': Dataset.from_pandas(df_s1_train, preserve_index=False),\n",
        "    'val': Dataset.from_pandas(df_s1_val, preserve_index=False),\n",
        "    'test': Dataset.from_pandas(df_s1_test, preserve_index=False)\n",
        "}\n",
        "\n",
        "s1_model = SetFitModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                                       labels=[\"Important\", \"Not Important\"],\n",
        "                                       device=DEVICE)\n",
        "s1_args = TrainingArguments(\n",
        "    num_iterations=20, # meaning?\n",
        "    seed=0,\n",
        "    eval_steps=500, # eval step -> 100\n",
        "    load_best_model_at_end=True,\n",
        "    num_epochs=(2, 16), # hpt on epochs on embedding stage - 2, 4, 8\n",
        "    batch_size=(32, 32) # emb batch size, classification stage batch size.\n",
        ")\n",
        "s1_trainer = Trainer(\n",
        "    model=s1_model,\n",
        "    args=s1_args,\n",
        "    train_dataset=s1_ds['train'],\n",
        "    eval_dataset=s1_ds['val'],\n",
        "    column_mapping={'body': 'text', 'important': 'label'}\n",
        ")\n",
        "s1_trainer.train()"
      ],
      "metadata": {
        "id": "s1ypcQ0oteaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model\n",
        "import joblib\n",
        "s1_model = joblib.load('/content/drive/MyDrive/Zivy Files/s1_model_24_apr.model')\n",
        "\n",
        "s1_ds = {\n",
        "    'train': Dataset.from_pandas(df_s1_train, preserve_index=False),\n",
        "    'val': Dataset.from_pandas(df_s1_val, preserve_index=False),\n",
        "    'test': Dataset.from_pandas(df_s1_test, preserve_index=False)\n",
        "}"
      ],
      "metadata": {
        "id": "oBo_U6F7FEbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On validation split\n",
        "import plotly.express as px\n",
        "\n",
        "prob_preds = s1_model.predict_proba(s1_ds['val']['body'])[:,1]\n",
        "true_labels = s1_ds['val']['important']\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, prob_preds)\n",
        "\n",
        "# The histogram of scores compared to true labels\n",
        "fig_hist = px.histogram(\n",
        "    x=prob_preds, color=true_labels, nbins=50,\n",
        "    labels=dict(color='True Labels', x='Score')\n",
        ")\n",
        "\n",
        "fig_hist.show()\n",
        "\n",
        "\n",
        "# Evaluating model performance at various thresholds\n",
        "df = pd.DataFrame({\n",
        "    'False Positive Rate': fpr,\n",
        "    'True Positive Rate': tpr\n",
        "}, index=thresholds)\n",
        "df.index.name = \"Thresholds\"\n",
        "df.columns.name = \"Rate\"\n",
        "\n",
        "fig_thresh = px.line(\n",
        "    df, title='TPR and FPR at every threshold',\n",
        "    width=700, height=500\n",
        ")\n",
        "\n",
        "fig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "fig_thresh.update_xaxes(range=[0, 1], constrain='domain')\n",
        "fig_thresh.show()"
      ],
      "metadata": {
        "id": "JBsBlvD4tneO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On test split\n",
        "s1_threshold = 0.1875164  # threshold chosen from ROC\n",
        "prob_preds = s1_model.predict_proba(s1_ds['test']['body'])[:,1]\n",
        "true_labels = s1_ds['test']['important']\n",
        "binary_preds = (prob_preds.numpy() >= s1_threshold).astype(int)\n",
        "\n",
        "report = classification_report(true_labels, binary_preds)\n",
        "\n",
        "print(f\"\\n--- CLASSIFICATION REPORT ---\\n{report}\")\n",
        "cf_matrix = confusion_matrix(true_labels, binary_preds)\n",
        "print(\"\\n --- CONFUSION MATRIX ---\\n\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, display_labels=[\"Not Important\", \"Important\"])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "rAlI0Uczt6a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyper-parameter Search"
      ],
      "metadata": {
        "id": "fUncwmP8vLoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparameter_search_s1_function(trial):\n",
        "    return {\n",
        "        \"num_epochs\": trial.suggest_categorical(\"num_epochs\", [2, 4, 8])\n",
        "    }"
      ],
      "metadata": {
        "id": "qvuioKB_vN0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(params=None):\n",
        "    return SetFitModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                                       labels=[\"Important\", \"Not Important\"],\n",
        "                                       device=DEVICE)"
      ],
      "metadata": {
        "id": "QDFVOh5Kw6ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1_model = SetFitModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                                       labels=[\"Important\", \"Not Important\"],\n",
        "                                       device=DEVICE)\n",
        "s1_args = TrainingArguments(\n",
        "    num_iterations=20, # meaning?\n",
        "    seed=0,\n",
        "    eval_steps=100, # eval step -> 100\n",
        "    load_best_model_at_end=True,\n",
        "    num_epochs=8,\n",
        "    batch_size=(32, 32) # emb batch size, classification stage batch size.\n",
        ")\n",
        "s1_trainer = Trainer(\n",
        "    model=s1_model,\n",
        "    args=s1_args,\n",
        "    train_dataset=s1_ds['train'],\n",
        "    eval_dataset=s1_ds['val'],\n",
        "    column_mapping={'body': 'text', 'important': 'label'}\n",
        ")"
      ],
      "metadata": {
        "id": "0JOAuydjvfwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1_trainer.train()"
      ],
      "metadata": {
        "id": "hTfC2_GDzhgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.visualization.matplotlib import plot_param_importances\n",
        "\n",
        "plot_param_importances(best.backend);"
      ],
      "metadata": {
        "id": "euy9JjkAvyMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 2"
      ],
      "metadata": {
        "id": "jNqxrbm1uAg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s2_ds = {\n",
        "    'train': Dataset.from_pandas(df_s2_train, preserve_index=False),\n",
        "    'val': Dataset.from_pandas(df_s2_val, preserve_index=False)\n",
        "}\n",
        "\n",
        "s2_model = SetFitModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                                       labels=[\"Action Items\", \"FYI\"],\n",
        "                                       device=DEVICE)\n",
        "s2_args = TrainingArguments(\n",
        "    num_iterations=20,\n",
        "    seed=0,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=500,\n",
        "    load_best_model_at_end=True,\n",
        "    num_epochs=(2, 16),\n",
        "    batch_size=(32, 32) # emb batch size, classification stage batch size.\n",
        ")\n",
        "s2_trainer = Trainer(\n",
        "    model=s2_model,\n",
        "    args=s2_args,\n",
        "    train_dataset=s2_ds['train'],\n",
        "    eval_dataset=s2_ds['val'],\n",
        "    column_mapping={'body': 'text', 'category': 'label'}\n",
        ")\n",
        "\n",
        "s2_trainer.train()"
      ],
      "metadata": {
        "id": "zSNYYxScuBNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "s2_model = joblib.load('/content/drive/MyDrive/Zivy Files/s2_model_24_apr.model')\n",
        "\n",
        "s2_ds = {\n",
        "    'train': Dataset.from_pandas(df_s2_train, preserve_index=False),\n",
        "    'val': Dataset.from_pandas(df_s2_val, preserve_index=False)\n",
        "}"
      ],
      "metadata": {
        "id": "Rs9BakEKFlWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_preds = s2_model.predict_proba(s2_ds['val']['body'])[:,1]"
      ],
      "metadata": {
        "id": "lwvBv-EyI-0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_s2_val['prob_pred'] = prob_preds"
      ],
      "metadata": {
        "id": "bJWkPvgIJCuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_s2_val[(df_s2_val['category'] == \"Action Items\") & (df_s2_val['prob_pred']>0.8)]"
      ],
      "metadata": {
        "id": "JcYV2GHnIdnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_preds = s2_model.predict_proba(s2_ds['val']['body'])[:,1] # getting 0 for action items' probability\n",
        "true_labels = s2_ds['val']['category']\n",
        "mapping = {'Action Items': 0, 'FYI': 1}\n",
        "mapped_list = [mapping[item] for item in true_labels]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(mapped_list, prob_preds)\n",
        "\n",
        "# The histogram of scores compared to true labels\n",
        "fig_hist = px.histogram(\n",
        "    x=prob_preds, color=mapped_list, nbins=50,\n",
        "    labels=dict(color='True Labels', x='Score')\n",
        ")\n",
        "\n",
        "fig_hist.show()\n",
        "\n",
        "\n",
        "# Evaluating model performance at various thresholds\n",
        "df = pd.DataFrame({\n",
        "    'False Positive Rate': fpr,\n",
        "    'True Positive Rate': tpr\n",
        "}, index=thresholds)\n",
        "df.index.name = \"Thresholds\"\n",
        "df.columns.name = \"Rate\"\n",
        "\n",
        "fig_thresh = px.line(\n",
        "    df, title='TPR and FPR at every threshold',\n",
        "    width=700, height=500\n",
        ")\n",
        "\n",
        "fig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "fig_thresh.update_xaxes(range=[0, 1], constrain='domain')\n",
        "fig_thresh.show()"
      ],
      "metadata": {
        "id": "0URnuSZquELE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2_threshold = 0.1579706  # threshold chosen from ROC\n",
        "# try different thresholds to increase recall of action items.\n",
        "prob_preds = s2_model.predict_proba(s2_ds['val']['body'])[:,1] # getting 0 for action items' probability\n",
        "true_labels = s2_ds['val']['category']\n",
        "mapping = {'Action Items': 0, 'FYI': 1}\n",
        "mapped_list = [mapping[item] for item in true_labels]\n",
        "binary_preds = (prob_preds.numpy() >= s2_threshold).astype(int)\n",
        "report = classification_report(mapped_list, binary_preds)\n",
        "\n",
        "print(f\"\\n--- CLASSIFICATION REPORT ---\\n{report}\")\n",
        "cf_matrix = confusion_matrix(mapped_list, binary_preds)\n",
        "print(\"\\n --- CONFUSION MATRIX ---\\n\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, display_labels=[\"Action Items\", \"FYI\"])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "FSECKK89uGO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble"
      ],
      "metadata": {
        "id": "Y2qmQt4HvkAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble_predictor(message_body):\n",
        "    s1_imp_proba_pred = s1_model.predict_proba([message_body]).numpy()[0][1]\n",
        "    if s1_imp_proba_pred >= s1_threshold:\n",
        "        s2_ai_proba_pred = s2_model.predict_proba([message_body]).numpy()[0][1]\n",
        "\n",
        "        if s2_ai_proba_pred >= s2_threshold:\n",
        "            return 'FYI'\n",
        "        else:\n",
        "            return 'Action Items'\n",
        "    else:\n",
        "        return 'Not Important'"
      ],
      "metadata": {
        "id": "-Nbp2PonvkyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "y_true = df_s1_test['category'].values\n",
        "\n",
        "for i, row in df_s1_test.iterrows():\n",
        "    y_pred.append(ensemble_predictor(row['body']))\n",
        "\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "print(f\"\\n--- CLASSIFICATION REPORT ---\\n{report}\")\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\n --- CONFUSION MATRIX ---\\n\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, display_labels=[\"Action Items\", \"FYI\", \"Not Important\"])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "qF8gUSzIvrDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance on bot messages\n",
        "eval_df_bot = df_s1_test[df_s1_test['channel_name'].isin(['deployments', 'form-publish-alerts',\n",
        "                'form-generated-alerts', 'shortcut-updates',\n",
        "                'demo-form-filled-alerts', 'sentry-errors', 'watchdog_engine',\n",
        "                'aws-updates', 'ph-reviews', 'new-user-alerts', 'dc-sentry', 'dc-alerts'])]\n",
        "\n",
        "y_pred = []\n",
        "y_true = eval_df_bot['category'].values\n",
        "\n",
        "for i, row in eval_df_bot.iterrows():\n",
        "    y_pred.append(ensemble_predictor(row['body']))\n",
        "\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "print(f\"\\n--- CLASSIFICATION REPORT ---\\n{report}\")\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\n --- CONFUSION MATRIX ---\\n\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, display_labels=[\"Action Items\",\"FYI\", \"Not Important\"]) # there are no action items from bot messages in this df\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "ZA6tNsfUvuO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance on non-bot messages\n",
        "eval_df_non_bot = df_s1_test[~df_s1_test['channel_name'].isin([ 'deployments', 'form-publish-alerts',\n",
        "                        'form-generated-alerts',  'shortcut-updates',\n",
        "                        'demo-form-filled-alerts',  'sentry-errors', 'watchdog_engine',\n",
        "                        'aws-updates', 'ph-reviews', 'new-user-alerts',  'dc-sentry',  'dc-alerts'])]\n",
        "y_pred = []\n",
        "y_true = eval_df_non_bot['category'].values\n",
        "\n",
        "for i, row in eval_df_non_bot.iterrows():\n",
        "    y_pred.append(ensemble_predictor(row['body']))\n",
        "\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "print(f\"\\n--- CLASSIFICATION REPORT ---\\n{report}\")\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\n --- CONFUSION MATRIX ---\\n\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, display_labels=[\"Action Items\", \"FYI\", \"Not Important\"]) # there are no action items from bot messages in this df\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "B_f9WWjjvzLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loss plot\n",
        "steps = []\n",
        "losses = []\n",
        "for x in s1_model.__dict__['model_card_data']['eval_lines_list']:\n",
        "    steps.append(x['Step'])\n",
        "    losses.append(x['Training Loss'])\n",
        "plt.plot(steps, losses)\n",
        "plt.xlabel(\"Steps\")  # add X-axis label\n",
        "plt.ylabel(\"Train Loss\")  # add Y-axis label\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p24HH_uimVDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1_model = s1_model.to('cpu')\n",
        "s2_model = s2_model.to('cpu')\n",
        "import joblib\n",
        "joblib.dump(s1_model, '/content/drive/MyDrive/Zivy Files/s1_model_24_apr.model')\n",
        "joblib.dump(s2_model, '/content/drive/MyDrive/Zivy Files/s2_model_24_apr.model')"
      ],
      "metadata": {
        "id": "OMFL8jyBk7Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameter tuning"
      ],
      "metadata": {
        "id": "Y4Pv7tTat62X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q optuna"
      ],
      "metadata": {
        "id": "XfzIRj8Ct-HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture New"
      ],
      "metadata": {
        "id": "euxBojimp0wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q pytorch-lightning sentence-transformers"
      ],
      "metadata": {
        "id": "640w32ZPp_jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "Ogb_zZvbq3fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from ast import literal_eval\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "class MessageClassificationDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, emb_model: str = 'all-MiniLM-L6-v2', output_field_name='category'):\n",
        "        self.data = df\n",
        "        self.embedding_model = embedding_model\n",
        "        self.embedding_size = self.embedding_model.get_sentence_embedding_dimension()\n",
        "        self.n_previous_msgs = 3\n",
        "        self.n_future_msgs = 1\n",
        "        self.output_field_name = output_field_name\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _padded_embeddings(self, str_list: List[str], out_rows: int):\n",
        "        if not str_list:\n",
        "            return np.zeros((out_rows, self.embedding_size))  # Return an all-zero array\n",
        "        else:\n",
        "            embeddings = [self.embedding_model.encode(s) for s in str_list]\n",
        "            padded_embeddings = np.zeros((out_rows, self.embedding_size))\n",
        "            padded_embeddings[:len(embeddings)] = np.array(embeddings)\n",
        "\n",
        "            return padded_embeddings\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data.iloc[index]\n",
        "        message_embs = self._padded_embeddings([row['body']], 1)\n",
        "        previous_embs = self._padded_embeddings(row['previous_messages'], self.n_previous_msgs)\n",
        "        future_embs = self._padded_embeddings(row['future_messages'], self.n_future_msgs)\n",
        "        embedding = np.concatenate((message_embs, previous_embs, future_embs), axis=0)\n",
        "        mapping = {\n",
        "            'Action Items': 0,\n",
        "            \"FYI\": 1,\n",
        "            \"Not Important\": 2\n",
        "        }\n",
        "        y = [mapping[row[self.output_field_name]]]\n",
        "        item = {\n",
        "            'embedding': torch.from_numpy(embedding.reshape(-1,)).float(),\n",
        "            'category': torch.as_tensor(y)\n",
        "        }\n",
        "\n",
        "        return item\n",
        "\n",
        "\n",
        "class MessageClassificationDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, csv_path: str, batch_size: int = 32):\n",
        "        super().__init__()\n",
        "        df = pd.read_csv(csv_path)\n",
        "        df.dropna(subset=['category'], how='all', inplace=True) # these nan's are coming from skipped labelling messages\n",
        "        df = df[['body', 'category', 'channel_name', 'previous_messages', 'future_messages']]\n",
        "        df['important'] = df['category'].apply(lambda x: 1 if x in ['FYI', 'Action Items'] else 0)\n",
        "        df['previous_messages'] = df['previous_messages'].apply(literal_eval)\n",
        "        df['future_messages'] = df['future_messages'].apply(literal_eval)\n",
        "        df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['category'], random_state=0)\n",
        "        df_train, df_val = train_test_split(df_train, test_size=0.1, stratify=df_train['category'], random_state=0)\n",
        "\n",
        "        self.train = MessageClassificationDataset(df_train) #72%\n",
        "        self.val = MessageClassificationDataset(df_val) # 8%\n",
        "        self.test = MessageClassificationDataset(df_test)# 20%\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test, batch_size=self.batch_size)\n",
        "\n",
        "class MessageClassifier(nn.Module):\n",
        "    def __init__(self, emb_size):\n",
        "        super(MessageClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(5*emb_size, 64)  # dense layer 1\n",
        "        self.fc2 = nn.Linear(64, 64)  # dense layer 2\n",
        "        self.fc3 = nn.Linear(64, 3)  # output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # ReLU activation in dense layers\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class LitMessageClassifier(pl.LightningModule):\n",
        "    def __init__(self, model, learning_rate=1e-3):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        X = batch['embedding']\n",
        "        y_hat = self.model(X) # logits\n",
        "        mapping = {\n",
        "            'Action Items': 0,\n",
        "            \"FYI\": 1,\n",
        "            \"Not Important\": 2\n",
        "        }\n",
        "        y = batch['category'].reshape(-1,)\n",
        "\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        X = batch['embedding']\n",
        "        y_hat = self.model(X) # logits\n",
        "        mapping = {\n",
        "            'Action Items': 0,\n",
        "            \"FYI\": 1,\n",
        "            \"Not Important\": 2\n",
        "        }\n",
        "        y = batch['category'].reshape(-1,)\n",
        "\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "dm = MessageClassificationDataModule(csv_path=\"/content/drive/MyDrive/Zivy Files/labelled_17_apr.csv\")\n",
        "model = LitMessageClassifier(\n",
        "    model=MessageClassifier(emb_size=dm.train.embedding_size),\n",
        "    learning_rate=0.002754228703338169\n",
        ")\n",
        "early_stopping = EarlyStopping('val_loss', patience=5)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    save_top_k=1,\n",
        "    mode='min',\n",
        "    filename='best_model.ckpt'\n",
        ")\n",
        "\n",
        "# pl.seed_everything(0, workers=True)\n",
        "# Got RunTime Error for doing seed everything\n",
        "# RuntimeError: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility\n",
        "trainer = pl.Trainer(accelerator=\"cuda\", devices=1, callbacks=[checkpoint_callback, early_stopping])\n",
        "trainer.fit(model=model, datamodule=dm)"
      ],
      "metadata": {
        "id": "arXdXtTep0SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = []\n",
        "y_pred = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in dm.test_dataloader():\n",
        "        X = batch['embedding']\n",
        "        y = batch['category']\n",
        "        y_hat = model.model(X) # logits\n",
        "        probabilities = F.softmax(y_hat, dim=1)\n",
        "        top_p, top_class = probabilities.topk(1, dim = 1)\n",
        "        y_true.extend(list(y.numpy().reshape(-1,)))\n",
        "        y_pred.extend(list(top_class.numpy().reshape(-1,)))\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "CLM6cmid6z2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = pl.tuner.tuning.Tuner(trainer=trainer)\n",
        "lr_finder = t.lr_find(model=model, datamodule=dm)\n",
        "# Results can be found in\n",
        "print(lr_finder.results)\n",
        "\n",
        "# Plot with\n",
        "fig = lr_finder.plot(suggest=True)\n",
        "fig.show()\n",
        "\n",
        "# Pick point based on plot, or get suggestion\n",
        "new_lr = lr_finder.suggestion()"
      ],
      "metadata": {
        "id": "eWzgZuo3qEj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_lr"
      ],
      "metadata": {
        "id": "MP2L3-qs0hUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qmIcNJu0hfb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}